{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20806124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pydub import AudioSegment\n",
    "\n",
    "# input_root = \"audio\"\n",
    "# output_root = \"audio_wav\"\n",
    "\n",
    "# for subdir in os.listdir(input_root):\n",
    "#     input_subdir = os.path.join(input_root, subdir)\n",
    "#     output_subdir = os.path.join(output_root, subdir)\n",
    "\n",
    "#     if not os.path.isdir(input_subdir):\n",
    "#         continue\n",
    "\n",
    "#     os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "#     for filename in os.listdir(input_subdir):\n",
    "#         if filename.endswith(\".mp3\"):\n",
    "#             input_path = os.path.join(input_subdir, filename)\n",
    "#             output_path = os.path.join(output_subdir, filename.replace(\".mp3\", \".wav\"))\n",
    "\n",
    "#             try:\n",
    "#                 audio = AudioSegment.from_mp3(input_path)\n",
    "#                 audio = audio.set_channels(1).set_frame_rate(32000)\n",
    "#                 audio.export(output_path, format=\"wav\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"⚠️ Failed to convert: {input_path}\")\n",
    "#                 print(f\"   Reason: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af5016f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>no voice</th>\n",
       "      <th>singer</th>\n",
       "      <th>duet</th>\n",
       "      <th>plucking</th>\n",
       "      <th>hard rock</th>\n",
       "      <th>world</th>\n",
       "      <th>bongos</th>\n",
       "      <th>harpsichord</th>\n",
       "      <th>female singing</th>\n",
       "      <th>...</th>\n",
       "      <th>rap</th>\n",
       "      <th>metal</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>quick</th>\n",
       "      <th>water</th>\n",
       "      <th>baroque</th>\n",
       "      <th>women</th>\n",
       "      <th>fiddle</th>\n",
       "      <th>english</th>\n",
       "      <th>mp3_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f/american_bach_soloists-j_s__bach_solo_cantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c/lvx_nova-lvx_nova-01-contimune-30-59.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c/lvx_nova-lvx_nova-01-contimune-175-204.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c/lvx_nova-lvx_nova-01-contimune-233-262.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c/lvx_nova-lvx_nova-01-contimune-291-320.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0/american_bach_soloists-j_s__bach__cantatas_v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clip_id  no voice  singer  duet  plucking  hard rock  world  bongos  \\\n",
       "0        2         0       0     0         0          0      0       0   \n",
       "1        6         0       0     0         0          0      0       0   \n",
       "2       10         0       0     0         0          0      0       0   \n",
       "3       11         0       0     0         0          0      0       0   \n",
       "4       12         0       0     0         0          0      0       0   \n",
       "5       14         0       0     0         0          0      0       0   \n",
       "6       19         0       0     0         0          0      0       0   \n",
       "7       21         0       0     0         0          0      0       0   \n",
       "8       23         0       0     0         0          0      0       0   \n",
       "9       25         0       0     0         0          0      0       0   \n",
       "\n",
       "   harpsichord  female singing  ...  rap  metal  hip hop  quick  water  \\\n",
       "0            0               0  ...    0      0        0      0      0   \n",
       "1            0               0  ...    0      0        0      0      0   \n",
       "2            0               0  ...    0      0        0      0      0   \n",
       "3            0               0  ...    0      0        0      0      0   \n",
       "4            0               0  ...    0      0        0      0      0   \n",
       "5            0               0  ...    0      0        0      0      0   \n",
       "6            0               0  ...    0      0        0      0      0   \n",
       "7            0               0  ...    0      0        0      0      0   \n",
       "8            0               0  ...    0      0        0      0      0   \n",
       "9            0               0  ...    0      0        0      0      0   \n",
       "\n",
       "   baroque  women  fiddle  english  \\\n",
       "0        0      0       0        0   \n",
       "1        1      0       0        0   \n",
       "2        0      0       0        0   \n",
       "3        0      0       0        0   \n",
       "4        0      0       0        0   \n",
       "5        0      0       0        0   \n",
       "6        0      0       0        0   \n",
       "7        0      0       0        0   \n",
       "8        0      0       0        0   \n",
       "9        0      0       0        0   \n",
       "\n",
       "                                            mp3_path  \n",
       "0  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "1  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "2  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "3  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "4  f/american_bach_soloists-j_s__bach_solo_cantat...  \n",
       "5         c/lvx_nova-lvx_nova-01-contimune-30-59.mp3  \n",
       "6       c/lvx_nova-lvx_nova-01-contimune-175-204.mp3  \n",
       "7       c/lvx_nova-lvx_nova-01-contimune-233-262.mp3  \n",
       "8       c/lvx_nova-lvx_nova-01-contimune-291-320.mp3  \n",
       "9  0/american_bach_soloists-j_s__bach__cantatas_v...  \n",
       "\n",
       "[10 rows x 190 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded CSV file\n",
    "csv_path = \"./annotations_final.csv\"\n",
    "df = pd.read_csv(csv_path, sep=\"\\t\")\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ba0745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 25863 rows\n"
     ]
    }
   ],
   "source": [
    "# size of the dataset\n",
    "print(f\"Dataset size: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131ef8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./audio_wav/magnatagatune_text_audio_pairs.jsonl'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Get the tag columns (all except clip_id and mp3_path)\n",
    "tag_columns = df.columns.difference(['clip_id', 'mp3_path'])\n",
    "\n",
    "# Output list\n",
    "samples = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    tags = [tag.replace(\"_\", \" \") for tag in tag_columns if row[tag] == 1]\n",
    "    if not tags:\n",
    "        continue  # skip samples with no tags\n",
    "    \n",
    "    # Generate simple natural language prompt\n",
    "    prompt = f\"A music clip with \" + \", \".join(tags[:-1]) + (\" and \" + tags[-1] if len(tags) > 1 else tags[0]) + \".\"\n",
    "\n",
    "    samples.append({\n",
    "        \"audio_filepath\": f\"audio_wav/{row['mp3_path'].replace('.mp3', '.wav')}\",\n",
    "        \"text\": prompt\n",
    "    })\n",
    "\n",
    "# Save to JSONL\n",
    "jsonl_path = \"./audio_wav/magnatagatune_text_audio_pairs.jsonl\"\n",
    "with open(jsonl_path, \"w\") as f:\n",
    "    for sample in samples:\n",
    "        f.write(json.dumps(sample) + \"\\n\")\n",
    "\n",
    "jsonl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "374af278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio_wav/f/american_bach_soloists-j_s__bach_solo_cantatas-01-bwv54__i_aria-30-59.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/american_bach_soloists-j_s__bach_solo_cantatas-01-bwv54__i_aria-146-175.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/american_bach_soloists-j_s__bach_solo_cantatas-01-bwv54__i_aria-262-291.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/american_bach_soloists-j_s__bach_solo_cantatas-01-bwv54__i_aria-291-320.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/american_bach_soloists-j_s__bach_solo_cantatas-01-bwv54__i_aria-320-349.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/c/lvx_nova-lvx_nova-01-contimune-30-59.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/c/lvx_nova-lvx_nova-01-contimune-233-262.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/c/lvx_nova-lvx_nova-01-contimune-291-320.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/0/american_bach_soloists-j_s__bach__cantatas_volume_v-01-gleichwie_der_regen_und_schnee_vom_himmel_fallt_bwv_18_i_sinfonia-117-146.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/e/steven_devine-portrait_of_an_english_harpsichord-01-lesson_1_in_g_major_prelude_james_nares-0-29.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/e/steven_devine-portrait_of_an_english_harpsichord-01-lesson_1_in_g_major_prelude_james_nares-30-59.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/the_headroom_project-jetuton_andawai-01-linda_morena-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/the_headroom_project-jetuton_andawai-01-linda_morena-88-117.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-0-29.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-30-59.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-146-175.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-262-291.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-291-320.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-320-349.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-349-378.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-407-436.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-494-523.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-697-726.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-784-813.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-813-842.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-929-958.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-987-1016.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-1016-1045.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-1074-1103.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-1132-1161.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-1161-1190.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-1190-1219.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-1219-1248.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-1248-1277.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-1277-1306.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-1306-1335.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-1335-1364.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/6/ralph_meulenbroeks-gambomania-01-my_mistress_hath_a_pritty_thing_tobias_hume-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/6/ralph_meulenbroeks-gambomania-01-my_mistress_hath_a_pritty_thing_tobias_hume-88-117.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/6/ralph_meulenbroeks-gambomania-01-my_mistress_hath_a_pritty_thing_tobias_hume-117-146.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/6/ralph_meulenbroeks-gambomania-01-my_mistress_hath_a_pritty_thing_tobias_hume-175-204.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/philharmonia_baroque_orchestra-jake_heggie__to_hell_and_back-01-overture-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/philharmonia_baroque_orchestra-jake_heggie__to_hell_and_back-01-overture-88-117.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/philharmonia_baroque_orchestra-jake_heggie__to_hell_and_back-01-overture-117-146.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/0/rocket_city_riot-last_of_the_pleasure_seekers-01-under_the_bright_lights-30-59.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/0/rocket_city_riot-last_of_the_pleasure_seekers-01-under_the_bright_lights-146-175.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/tilopa-turkishauch-01-1x3-0-29.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/tilopa-turkishauch-01-1x3-30-59.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/tilopa-turkishauch-01-1x3-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/tilopa-turkishauch-01-1x3-88-117.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/tilopa-turkishauch-01-1x3-117-146.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/tilopa-turkishauch-01-1x3-146-175.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/tilopa-turkishauch-01-1x3-204-233.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/tilopa-turkishauch-01-1x3-233-262.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/tilopa-turkishauch-01-1x3-378-407.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/0/williamson-a_few_things_to_hear_before_we_all_blow_up-01-2_percent_er-88-117.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/0/williamson-a_few_things_to_hear_before_we_all_blow_up-01-2_percent_er-117-146.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/0/williamson-a_few_things_to_hear_before_we_all_blow_up-01-2_percent_er-146-175.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-204-233.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-233-262.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-262-291.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-291-320.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-320-349.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-378-407.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-407-436.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-465-494.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-494-523.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-581-610.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/5/new_york_consort_of_viols-dances_and_canzonas_of_holborne_and_brade-01-3_almaines_holborne-610-639.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/6/mercy_machine-the_devil_i_know-01-30_years-88-117.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/6/mercy_machine-the_devil_i_know-01-30_years-117-146.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/6/mercy_machine-the_devil_i_know-01-30_years-233-262.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/6/mercy_machine-the_devil_i_know-01-30_years-262-291.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/a/liquid_zen-magic_midsummer-01-4_oclock_sunny_and_hot-30-59.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/a/liquid_zen-magic_midsummer-01-4_oclock_sunny_and_hot-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/a/liquid_zen-magic_midsummer-01-4_oclock_sunny_and_hot-88-117.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/e/burning_babylon-stereo_mash_up-01-7_nine_skank-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/e/burning_babylon-stereo_mash_up-01-7_nine_skank-88-117.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/e/burning_babylon-stereo_mash_up-01-7_nine_skank-146-175.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/e/burning_babylon-stereo_mash_up-01-7_nine_skank-175-204.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/pain_factor-8_seconds-01-8_seconds-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/pain_factor-8_seconds-01-8_seconds-88-117.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/pain_factor-8_seconds-01-8_seconds-117-146.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/pain_factor-8_seconds-01-8_seconds-175-204.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/the_seldon_plan-making_circles-01-a_rhyming_dictionary-30-59.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/the_seldon_plan-making_circles-01-a_rhyming_dictionary-175-204.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/c/mountain_mirrors-lunar_ecstasy-01-a_short_burst_of_clarity-30-59.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/c/mountain_mirrors-lunar_ecstasy-01-a_short_burst_of_clarity-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/c/mountain_mirrors-lunar_ecstasy-01-a_short_burst_of_clarity-88-117.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/c/mountain_mirrors-lunar_ecstasy-01-a_short_burst_of_clarity-146-175.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/professor_armchair-too_much_mustard-01-a_signal_from_mars-0-29.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/professor_armchair-too_much_mustard-01-a_signal_from_mars-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/professor_armchair-too_much_mustard-01-a_signal_from_mars-117-146.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/f/professor_armchair-too_much_mustard-01-a_signal_from_mars-262-291.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/b/jacob_heringman-jane_pickeringes_lute_book-01-a_toy-0-29.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/d/electric_frankenstein-sick_songs-01-action_high-117-146.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/9/the_wretch-ambulatory-01-admission-30-59.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/0/apa_ya-apa_ya-01-african_dance-59-88.wav with shape (931967,) and sample rate 32000\n",
      "Processing audio_wav/0/apa_ya-apa_ya-01-african_dance-88-117.wav with shape (931967,) and sample rate 32000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'audio_wav/magnatagatune_tokenized_32khz.jsonl'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EncodecModel, AutoProcessor\n",
    "import librosa\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model = EncodecModel.from_pretrained(\"facebook/encodec_32khz\").to(device)\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/encodec_32khz\")\n",
    "\n",
    "input_jsonl = \"audio_wav/magnatagatune_text_audio_pairs.jsonl\"\n",
    "output_jsonl = \"audio_wav/magnatagatune_tokenized_32khz.jsonl\"\n",
    "Path(input_jsonl).parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(output_jsonl).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAX_SAMPLES = 100\n",
    "\n",
    "with open(input_jsonl, \"r\") as fin, open(output_jsonl, \"w\") as fout:\n",
    "    for idx, line in enumerate(fin):\n",
    "        if idx >= MAX_SAMPLES:\n",
    "            break\n",
    "\n",
    "        item = json.loads(line)\n",
    "        audio_path = item[\"audio_filepath\"]\n",
    "\n",
    "        try:\n",
    "            waveform, sr = librosa.load(audio_path, sr=None, mono=True)\n",
    "            print(f\"Processing {audio_path} with shape {waveform.shape} and sample rate {sr}\")\n",
    "            inputs = processor(raw_audio=waveform, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                codes = outputs.audio_codes[0].cpu().tolist()\n",
    "\n",
    "            item[\"audio_tokens\"] = codes\n",
    "            fout.write(json.dumps(item) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed on {audio_path}: {e}\")\n",
    "\n",
    "output_jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2bc3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'audio_wav/flattened_token_with_text_embedding.jsonl'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import json\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "text_encoder = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "text_encoder.eval()\n",
    "\n",
    "input_path = \"audio_wav/magnatagatune_tokenized_32khz.jsonl\"\n",
    "output_path = \"audio_wav/flattened_token_with_text_embedding.jsonl\"\n",
    "\n",
    "Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAX_SAMPLES = 100\n",
    "\n",
    "with open(input_path, \"r\") as fin, open(output_path, \"w\") as fout:\n",
    "    for idx, line in enumerate(fin):\n",
    "        if idx >= MAX_SAMPLES:\n",
    "            break\n",
    "\n",
    "        item = json.loads(line)\n",
    "        text = item[\"text\"]\n",
    "        tokens = item[\"audio_tokens\"] \n",
    "\n",
    "        try:\n",
    "            transposed = list(zip(*tokens)) \n",
    "            flattened = [tok for frame in transposed for tok in frame] \n",
    "\n",
    "            with torch.no_grad():\n",
    "                encoded = tokenizer(text, return_tensors=\"pt\")\n",
    "                embedding = text_encoder(**encoded).last_hidden_state.mean(dim=1).squeeze().tolist()\n",
    "\n",
    "            fout.write(json.dumps({\n",
    "                \"text\": text,\n",
    "                \"text_embedding\": embedding,\n",
    "                \"audio_flat_tokens\": flattened\n",
    "            }) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed on sample {idx}: {e}\")\n",
    "\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bb161aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'audio_wav/musicgen_dataset.pt'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from typing import List\n",
    "\n",
    "# 定义 Dataset 类\n",
    "class MusicGenDataset(Dataset):\n",
    "    def __init__(self, jsonl_path: str, max_audio_tokens: int = 1024):\n",
    "        self.data = []\n",
    "        with open(jsonl_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                # 截断音频 token，避免超长\n",
    "                audio_tokens = item[\"audio_flat_tokens\"][:max_audio_tokens]\n",
    "                text_embed = item[\"text_embedding\"]\n",
    "\n",
    "                # 拼接：text_embedding 虚拟为 N 个 tokens\n",
    "                # 假设 1 token = 1 vector，N = 8，简单将 text_embed 分块\n",
    "                embed_dim = 768\n",
    "                num_text_tokens = 8\n",
    "                if len(text_embed) != embed_dim:\n",
    "                    continue  # 跳过异常样本\n",
    "\n",
    "                # 扩展 text token embedding：形状 [8, 768]\n",
    "                text_tokens = torch.tensor(text_embed, dtype=torch.float).repeat(num_text_tokens, 1)\n",
    "                text_token_ids = torch.full((num_text_tokens,), -100)  # 无 label\n",
    "\n",
    "                # 拼接 input_ids 和 labels\n",
    "                MAX_AUDIO_TOKENS = 2048\n",
    "                flat_audio = [tok for frame in zip(*audio_tokens) for tok in frame]\n",
    "                flat_audio = flat_audio[:MAX_AUDIO_TOKENS + 1]\n",
    "                input_ids = torch.tensor(flat_audio[:-1], dtype=torch.long)  # [T]\n",
    "                labels    = torch.tensor(flat_audio[1:], dtype=torch.long)   # [T]\n",
    "\n",
    "                # 整合（text tokens 作为 prefix，没有 ID，仅影响 embedding）\n",
    "                self.data.append({\n",
    "                    \"text_embed\": text_tokens,         # shape: [N_text, 768]\n",
    "                    \"input_ids\": input_ids,            # shape: [T]\n",
    "                    \"labels\": labels,                  # shape: [T]\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# 构建 Dataset 并保存用于训练\n",
    "dataset_path = \"audio_wav/flattened_token_with_text_embedding.jsonl\"\n",
    "dataset = MusicGenDataset(dataset_path)\n",
    "\n",
    "# 保存为 .pt 文件\n",
    "torch.save(dataset, \"audio_wav/musicgen_dataset.pt\")\n",
    "\"audio_wav/musicgen_dataset.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "999bed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MusicGenTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=768, n_layers=6, n_heads=8):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.prefix_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=n_heads, dim_feedforward=2048, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.lm_head = nn.Linear(embed_dim, vocab_size)\n",
    "    def forward(self, text_embed, input_ids):\n",
    "        tok_emb = self.token_embedding(input_ids)   # [B, T, 768]\n",
    "        if tok_emb.dim() == 4:\n",
    "            tok_emb = tok_emb.squeeze(2)\n",
    "\n",
    "        prefix = self.prefix_proj(text_embed)       # [B, 8, 768]\n",
    "        x = torch.cat([prefix, tok_emb], dim=1)     # [B, 8+T, 768]\n",
    "\n",
    "        attn_mask = torch.triu(torch.ones(x.size(1), x.size(1)), 1).bool().to(x.device)\n",
    "        out = self.transformer(x, mask=attn_mask)\n",
    "        return self.lm_head(out[:, prefix.size(1):])  # return only audio token logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "605a5941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8, 768]) torch.Size([8, 2048]) torch.Size([8, 2048])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 16.20 GB, other allocations: 1.20 GB, max allowed: 18.13 GB). Tried to allocate 1.01 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m labels     = batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m].to(device)       \u001b[38;5;66;03m# [B, T]\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(text_embed.shape, input_ids.shape, labels.shape)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m logits = model(text_embed, input_ids)         \u001b[38;5;66;03m# [B, T, V]\u001b[39;00m\n\u001b[32m     16\u001b[39m loss = F.cross_entropy(logits.view(-\u001b[32m1\u001b[39m, logits.size(-\u001b[32m1\u001b[39m)), labels.view(-\u001b[32m1\u001b[39m))\n\u001b[32m     18\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mMusicGenTransformer.forward\u001b[39m\u001b[34m(self, text_embed, input_ids)\u001b[39m\n\u001b[32m     20\u001b[39m x = torch.cat([prefix, tok_emb], dim=\u001b[32m1\u001b[39m)     \u001b[38;5;66;03m# [B, 8+T, 768]\u001b[39;00m\n\u001b[32m     22\u001b[39m attn_mask = torch.triu(torch.ones(x.size(\u001b[32m1\u001b[39m), x.size(\u001b[32m1\u001b[39m)), \u001b[32m1\u001b[39m).bool().to(x.device)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m out = \u001b[38;5;28mself\u001b[39m.transformer(x, mask=attn_mask)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lm_head(out[:, prefix.size(\u001b[32m1\u001b[39m):])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:514\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    511\u001b[39m is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m     output = mod(\n\u001b[32m    515\u001b[39m         output,\n\u001b[32m    516\u001b[39m         src_mask=mask,\n\u001b[32m    517\u001b[39m         is_causal=is_causal,\n\u001b[32m    518\u001b[39m         src_key_padding_mask=src_key_padding_mask_for_layers,\n\u001b[32m    519\u001b[39m     )\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[32m    522\u001b[39m     output = output.to_padded_tensor(\u001b[32m0.0\u001b[39m, src.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:914\u001b[39m, in \u001b[36mTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    910\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m._ff_block(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    912\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m    913\u001b[39m         x\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m         + \u001b[38;5;28mself\u001b[39m._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal)\n\u001b[32m    915\u001b[39m     )\n\u001b[32m    916\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:928\u001b[39m, in \u001b[36mTransformerEncoderLayer._sa_block\u001b[39m\u001b[34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sa_block\u001b[39m(\n\u001b[32m    922\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    923\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    926\u001b[39m     is_causal: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    927\u001b[39m ) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.self_attn(\n\u001b[32m    929\u001b[39m         x,\n\u001b[32m    930\u001b[39m         x,\n\u001b[32m    931\u001b[39m         x,\n\u001b[32m    932\u001b[39m         attn_mask=attn_mask,\n\u001b[32m    933\u001b[39m         key_padding_mask=key_padding_mask,\n\u001b[32m    934\u001b[39m         need_weights=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    935\u001b[39m         is_causal=is_causal,\n\u001b[32m    936\u001b[39m     )[\u001b[32m0\u001b[39m]\n\u001b[32m    937\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/activation.py:1373\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1347\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1348\u001b[39m         query,\n\u001b[32m   1349\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1370\u001b[39m         is_causal=is_causal,\n\u001b[32m   1371\u001b[39m     )\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1374\u001b[39m         query,\n\u001b[32m   1375\u001b[39m         key,\n\u001b[32m   1376\u001b[39m         value,\n\u001b[32m   1377\u001b[39m         \u001b[38;5;28mself\u001b[39m.embed_dim,\n\u001b[32m   1378\u001b[39m         \u001b[38;5;28mself\u001b[39m.num_heads,\n\u001b[32m   1379\u001b[39m         \u001b[38;5;28mself\u001b[39m.in_proj_weight,\n\u001b[32m   1380\u001b[39m         \u001b[38;5;28mself\u001b[39m.in_proj_bias,\n\u001b[32m   1381\u001b[39m         \u001b[38;5;28mself\u001b[39m.bias_k,\n\u001b[32m   1382\u001b[39m         \u001b[38;5;28mself\u001b[39m.bias_v,\n\u001b[32m   1383\u001b[39m         \u001b[38;5;28mself\u001b[39m.add_zero_attn,\n\u001b[32m   1384\u001b[39m         \u001b[38;5;28mself\u001b[39m.dropout,\n\u001b[32m   1385\u001b[39m         \u001b[38;5;28mself\u001b[39m.out_proj.weight,\n\u001b[32m   1386\u001b[39m         \u001b[38;5;28mself\u001b[39m.out_proj.bias,\n\u001b[32m   1387\u001b[39m         training=\u001b[38;5;28mself\u001b[39m.training,\n\u001b[32m   1388\u001b[39m         key_padding_mask=key_padding_mask,\n\u001b[32m   1389\u001b[39m         need_weights=need_weights,\n\u001b[32m   1390\u001b[39m         attn_mask=attn_mask,\n\u001b[32m   1391\u001b[39m         average_attn_weights=average_attn_weights,\n\u001b[32m   1392\u001b[39m         is_causal=is_causal,\n\u001b[32m   1393\u001b[39m     )\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/functional.py:6410\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6407\u001b[39m k = k.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m   6408\u001b[39m v = v.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m-> \u001b[39m\u001b[32m6410\u001b[39m attn_output = scaled_dot_product_attention(\n\u001b[32m   6411\u001b[39m     q, k, v, attn_mask, dropout_p, is_causal\n\u001b[32m   6412\u001b[39m )\n\u001b[32m   6413\u001b[39m attn_output = (\n\u001b[32m   6414\u001b[39m     attn_output.permute(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m).contiguous().view(bsz * tgt_len, embed_dim)\n\u001b[32m   6415\u001b[39m )\n\u001b[32m   6417\u001b[39m attn_output = linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 16.20 GB, other allocations: 1.20 GB, max allowed: 18.13 GB). Tried to allocate 1.01 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "dataset = torch.load(\"audio_wav/musicgen_dataset.pt\", weights_only=False)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "model = MusicGenTransformer(vocab_size=1024).to(device)  # 设置为你的实际 vocab size\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch in loader:\n",
    "        text_embed = batch[\"text_embed\"].to(device)   # [B, 8, 768]\n",
    "        input_ids  = batch[\"input_ids\"].to(device)    # [B, T]\n",
    "        labels     = batch[\"labels\"].to(device)       # [B, T]\n",
    "        print(text_embed.shape, input_ids.shape, labels.shape)\n",
    "        logits = model(text_embed, input_ids)         # [B, T, V]\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: loss = {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
